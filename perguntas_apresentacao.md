# Poss√≠veis Perguntas da Apresenta√ß√£o
## Projeto: Classifica√ß√£o de C√¢ncer de Mama com Redes Neurais

---

## üìö PERGUNTAS CONCEITUAIS B√ÅSICAS

### **Q1: Por que escolheram redes neurais ao inv√©s de algoritmos mais simples como SVM ou Random Forest?**
**R:** Testamos m√∫ltiplos algoritmos como baseline. Redes neurais oferecem:
- Capacidade de aprender padr√µes n√£o-lineares complexos
- Flexibilidade na arquitetura
- Capacidade de generaliza√ß√£o com regulariza√ß√£o adequada
- Performance superior aos baselines (96.5% vs 95.1% da regress√£o log√≠stica)

### **Q2: Como voc√™s garantem que o modelo n√£o est√° apenas "decorando" os dados (overfitting)?**
**R:** Implementamos m√∫ltiplas t√©cnicas anti-overfitting:
- **Dropout (0.3)** em camadas ocultas
- **Valida√ß√£o cruzada 5-fold** estratificada
- **Train/Test split** rigoroso (80/20)
- **Early stopping** durante treinamento
- **Regulariza√ß√£o L2** nos hiperpar√¢metros

### **Q3: O que significa "supervisionado" e por que n√£o usaram aprendizado n√£o-supervisionado?**
**R:** 
- **Supervisionado:** Temos labels conhecidos (B/M) para treinar
- **N√£o-supervisionado (clustering):** Seria inadequado pois:
  - J√° conhecemos as classes (benigno/maligno)
  - N√£o queremos "descobrir" grupos, queremos predizer classes conhecidas
  - Objetivo √© classifica√ß√£o, n√£o explora√ß√£o de padr√µes

---

## üî¨ PERGUNTAS T√âCNICAS SOBRE DADOS

### **Q4: Como voc√™s lidam com o desbalanceamento das classes (62.7% vs 37.3%)?**
**R:** 
- **Raz√£o 1.7:1** n√£o √© cr√≠tica (< 3:1)
- Usamos **stratified sampling** para manter propor√ß√µes
- M√©tricas balanceadas: **F1-score, Precision, Recall**
- Foco no **Recall** para casos malignos (mais cr√≠tico clinicamente)

### **Q5: Por que usar todas as 30 features? N√£o seria melhor fazer sele√ß√£o de features?**
**R:** Decis√£o baseada em:
- **Redes neurais s√£o robustas** √† alta dimensionalidade
- **Features "redundantes"** podem ter valor em combina√ß√£o
- **Regulariza√ß√£o (dropout)** previne overfitting
- **Benchmark** com literatura existente
- **30 features** ainda √© dimensionalidade gerenci√°vel

### **Q6: Como voc√™s validaram a qualidade dos dados originais?**
**R:**
- **Fonte cred√≠vel:** University of Wisconsin, >1000 cita√ß√µes
- **An√°lise de completude:** 0 dados faltantes nas features relevantes
- **An√°lise de outliers:** Mantidos por relev√¢ncia cl√≠nica
- **Consist√™ncia:** Padr√£o uniforme de coleta
- **Reprodutibilidade:** Dataset p√∫blico no Kaggle

### **Q7: Por que normaliza√ß√£o √© obrigat√≥ria neste caso?**
**R:**
- **Escalas muito diferentes:** area (100s-1000s) vs smoothness (0.05-0.16)
- **Sem normaliza√ß√£o:** Features com maior escala dominam o aprendizado
- **StandardScaler:** Padroniza m√©dia=0, desvio=1
- **Melhora converg√™ncia** e estabilidade do treinamento

---

## üèóÔ∏è PERGUNTAS SOBRE ARQUITETURA

### **Q8: Por que 64 e 32 neur√¥nios especificamente? Testaram outras configura√ß√µes?**
**R:**
- **64:** ~2x n√∫mero de features de entrada (regra emp√≠rica)
- **32:** Redu√ß√£o gradual para compress√£o de informa√ß√£o
- **Grid Search** testou outras configura√ß√µes
- **Baseado em literatura:** Arquiteturas similares para dados tabulares
- **Balanceio:** Capacidade vs simplicidade

### **Q9: Por que ReLU e n√£o outras fun√ß√µes de ativa√ß√£o como tanh ou sigmoid?**
**R:**
- **ReLU vantagens:**
  - Evita vanishing gradient
  - Computacionalmente eficiente
  - Cria esparsidade (alguns neur√¥nios inativos)
  - Estado da arte atual
- **Testamos outras:** Desempenho inferior no Grid Search

### **Q10: Por que Sigmoid na sa√≠da e n√£o Softmax?**
**R:**
- **Classifica√ß√£o bin√°ria:** Sigmoid suficiente (0-1)
- **Softmax:** Para m√∫ltiplas classes (>2)
- **Interpretabilidade:** Output como probabilidade
- **Compatibilidade:** Funciona com binary_crossentropy

### **Q11: Como definiram a taxa de Dropout (0.3)?**
**R:**
- **Valores testados:** 0.1, 0.2, 0.3, 0.5 no Grid Search
- **0.3 = 30%:** Balanceio entre regulariza√ß√£o e capacidade
- **Literatura:** Valores entre 0.2-0.5 s√£o comuns
- **Valida√ß√£o emp√≠rica:** Melhor performance na valida√ß√£o cruzada

---

## üìä PERGUNTAS SOBRE VALIDA√á√ÉO E M√âTRICAS

### **Q12: Por que Recall √© mais importante que Precision neste contexto?**
**R:**
- **Contexto m√©dico:** Pior perder um caso maligno (falso negativo)
- **Recall alto (97.8%):** Detectamos 97.8% dos casos malignos
- **Custo diferente:** Falso negativo = diagn√≥stico perdido (grave)
- **Falso positivo:** Exames adicionais (menos grave)

### **Q13: Como interpretam a matriz de confus√£o dos resultados?**
**R:**
- **True Negative (68):** Corretamente identificou benignos
- **True Positive (42):** Corretamente identificou malignos  
- **False Positive (3):** Benignos classificados como malignos
- **False Negative (1):** Maligno classificado como benigno
- **Resultado excelente:** Apenas 1 caso maligno perdido

### **Q14: Por que valida√ß√£o cruzada 5-fold e n√£o 10-fold?**
**R:**
- **Dataset pequeno (569):** 5-fold d√° splits maiores
- **Stratified:** Mant√©m propor√ß√£o das classes
- **Balanceio:** Variance vs bias das estimativas
- **Computacionalmente eficiente** para Grid Search
- **Literatura:** 5-fold adequado para datasets deste tamanho

### **Q15: Como comparam com benchmarks da literatura cient√≠fica?**
**R:**
- **Street et al. (1993):** 97.5% (linear programming)
- **Estudos recentes:** 93-98% (diversos algoritmos)
- **Nosso resultado:** 96.5% dentro da faixa esperada
- **Diferencial:** Metodologia reproduz√≠vel com valida√ß√£o rigorosa

---

## üéØ PERGUNTAS SOBRE APLICA√á√ÉO PR√ÅTICA

### **Q16: Este modelo poderia ser usado em produ√ß√£o real?**
**R:**
- **Limita√ß√µes atuais:**
  - Dataset de uma √∫nica institui√ß√£o
  - Falta valida√ß√£o externa
  - Aus√™ncia de dados cl√≠nicos adicionais
- **Pr√≥ximos passos necess√°rios:**
  - Valida√ß√£o multic√™ntrica
  - Dados de diferentes popula√ß√µes
  - Interface m√©dica adequada
  - Aprova√ß√£o regulat√≥ria

### **Q17: Como explicariam os resultados para um m√©dico?**
**R:**
- **Recall 97.8%:** "Detectamos 98 de cada 100 casos malignos"
- **Precision 95.2%:** "95% dos casos que marcamos como malignos realmente s√£o"
- **Suporte √† decis√£o:** N√£o substitui, mas auxilia o m√©dico
- **Segunda opini√£o:** Ferramenta adicional de diagn√≥stico

### **Q18: Quais s√£o os principais riscos/limita√ß√µes do modelo?**
**R:**
- **Vi√©s populacional:** Dados de uma √∫nica institui√ß√£o
- **Fatores n√£o inclu√≠dos:** Idade, hist√≥rico familiar, gen√©tica
- **Black box:** Dificulta interpretabilidade cl√≠nica
- **Drift:** Performance pode degradar com tempo
- **Depend√™ncia t√©cnica:** Requer infraestrutura adequada

---

## üîÑ PERGUNTAS SOBRE PROCESSO E METODOLOGIA

### **Q19: Como garantem a reprodutibilidade do experimento?**
**R:**
- **Seeds fixas:** SEED = 42 em todas as opera√ß√µes aleat√≥rias
- **Vers√µes espec√≠ficas:** Python 3.11.5, TensorFlow, etc.
- **Requirements.txt:** Todas as depend√™ncias documentadas
- **C√≥digo versionado:** GitHub com hist√≥rico completo
- **Documenta√ß√£o:** README detalhado

### **Q20: Se fossem fazer novamente, o que mudariam?**
**R:**
- **Dataset maior:** Buscar bases multic√™ntricas
- **Feature engineering:** Explorar intera√ß√µes entre features
- **Explicabilidade:** Implementar SHAP/LIME desde o in√≠cio
- **Ensembles:** Combinar m√∫ltiplos modelos
- **Valida√ß√£o temporal:** Se houvesse dados longitudinais

### **Q21: Como escolheram os hiperpar√¢metros para o Grid Search?**
**R:**
- **Literatura:** Valores comuns em papers similares
- **Experi√™ncia pr√©via:** Projetos anteriores da equipe
- **Recursos computacionais:** Limita√ß√µes de tempo/hardware
- **An√°lise explorat√≥ria:** Testes preliminares orientaram escolhas

---

## üí° PERGUNTAS CONCEITUAIS AVAN√áADAS

### **Q22: Como lidariam com concept drift em produ√ß√£o?**
**R:**
- **Monitoramento cont√≠nuo:** M√©tricas de performance
- **Retreinamento peri√≥dico:** Com novos dados
- **Detec√ß√£o de drift:** Compara√ß√£o distribui√ß√µes
- **Versionamento de modelos:** Rollback se necess√°rio

### **Q23: Por que n√£o usaram t√©cnicas de ensemble learning?**
**R:**
- **Escopo do projeto:** Foco em metodologia de RN
- **Complexidade:** Aumentaria dificuldade de interpreta√ß√£o
- **Performance:** Rede neural j√° atingiu objetivo
- **Pr√≥ximos passos:** Considerar√≠amos em vers√µes futuras

### **Q24: Como abordariam a quest√£o √©tica de IA em medicina?**
**R:**
- **Transpar√™ncia:** M√©dicos devem entender limita√ß√µes
- **Responsabilidade:** IA auxilia, m√©dico decide
- **Vi√©s:** Valida√ß√£o em popula√ß√µes diversas
- **Consentimento:** Pacientes sabem sobre uso de IA
- **Auditabilidade:** Decis√µes devem ser rastre√°veis

---

## üéì PERGUNTAS PARA APROFUNDAMENTO

### **Q25: Quais outras arquiteturas poderiam ser testadas?**
**R:**
- **Autoencoders:** Para detec√ß√£o de anomalias
- **Attention mechanisms:** Para identificar features importantes
- **Graph Neural Networks:** Se houvesse dados relacionais
- **Transfer Learning:** De modelos pr√©-treinados

### **Q26: Como avaliariam a import√¢ncia das features individualmente?**
**R:**
- **Correlation analysis:** J√° implementado
- **Permutation importance:** Sklearn
- **SHAP values:** Explicabilidade local/global
- **Feature ablation:** Remover e medir impacto
- **Gradient-based methods:** Para redes neurais

### **Q27: Como adaptar para outros tipos de c√¢ncer?**
**R:**
- **Transfer learning:** Usar camadas pr√©-treinadas
- **Fine-tuning:** Ajustar √∫ltima camada
- **Feature engineering:** Adaptar para novo dom√≠nio
- **Valida√ß√£o cruzada:** Entre tipos de c√¢ncer
- **Multi-task learning:** M√∫ltiplos c√¢nceres simultaneamente

---

## üìã DICAS PARA RESPONDER BEM

1. **Seja honesto sobre limita√ß√µes**
2. **Cite literatura quando relevante**
3. **Explique o racioc√≠nio por tr√°s das decis√µes**
4. **Use exemplos pr√°ticos quando poss√≠vel**
5. **Conecte aspectos t√©cnicos com impacto cl√≠nico**
6. **Mostre que consideram o contexto m√©dico**
7. **Demonstre pensamento cr√≠tico sobre o pr√≥prio trabalho**

---

*Este documento serve como prepara√ß√£o para poss√≠veis questionamentos durante a apresenta√ß√£o. Pratiquem as respostas, mas mantenham naturalidade e honestidade intelectual.*